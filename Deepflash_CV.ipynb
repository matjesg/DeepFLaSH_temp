{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation Notebook\n",
    "\n",
    "- [ ] Cora\n",
    "- [ ] Dennis\n",
    "- [ ] Manju\n",
    "- [ ] Corinna\n",
    "- [ ] GT\n",
    "- [ ] Cross Coder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !git clone https://github.com/matjesg/DeepFLaSH2.git /content/drive/My\\ Drive/DeepFLaSH2\n",
    "    %cd /content/drive/My\\ Drive/DeepFLaSH2\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import os\n",
    "from deepflash import unet, preproc, metrics, lr_finder, utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import skimage\n",
    "from skimage.measure import label\n",
    "from skimage.color import label2rgb\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP = 0\n",
    "CODER = ['gt']  #'rohini', 'dennis', 'cora', 'manju', 'corinna'\n",
    "NAME_PREFIX = 'falk'\n",
    "MASK = 'Parv' #cFOS\n",
    "IMAGE = 'green' #red\n",
    "CHANNELS_IMG = 1\n",
    "DATA_PATH = \"01_data\"\n",
    "MASK_PATH = \"data/labels\"\n",
    "ASSIGNMENT_PATH = 'samples_36_final.csv'\n",
    "TILE_SHAPE = (540,540)\n",
    "PADDING = (184,184)\n",
    "SEED = 0\n",
    "EL_SIZE = [635.9, 635.9] #micrometers\n",
    "CHECKPOINTS = 'checkpoints_cv'\n",
    "LOGDIR = 'logs_cv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETAINED = None# 'caffe/caffe_weights.h5' #None\n",
    "BATCH_NORM = False\n",
    "EPOCHS = 100\n",
    "CYCLIC_LR = 'triangular'\n",
    "SNAPSHOT_INTERVAL = 5\n",
    "N_SPLITS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 50 #50\n",
    "V_BAL = 0.1 #0.1\n",
    "SIGMA_BAL = 10 #10 \n",
    "SIGMA_SEP = 6 #6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel list with assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment = pd.read_csv(ASSIGNMENT_PATH, converters={'Nummer': lambda x: str(x).zfill(4)})\n",
    "assignment['Group_ID'] = assignment.groupby(['Kondition', 'Area']).ngroup()\n",
    "file_ids = assignment['Nummer'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [io.imread(os.path.join(DATA_PATH, img_name), as_gray=True) for \n",
    "              img_name in [s + '_' + IMAGE + '.tif' for s in file_ids]]\n",
    "\n",
    "image_list = [np.expand_dims(img, axis=2) for img in image_list]\n",
    "data = [{'rawdata': img, 'element_size_um': EL_SIZE} for img in image_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masks and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/data/DeepFLaSH2/data/labels/gt/0092_Parv.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e2a24ecd7769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCODER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     mask_list = [io.imread(os.path.join(MASK_PATH, coder, x), as_gray=True).astype('int')\n\u001b[0;32m----> 5\u001b[0;31m              for x in [s + '_' + MASK + '.tif' for s in file_ids]]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     pre = preproc.DataPreProcessor(element_size_um=None,\n",
      "\u001b[0;32m<ipython-input-11-e2a24ecd7769>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCODER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     mask_list = [io.imread(os.path.join(MASK_PATH, coder, x), as_gray=True).astype('int')\n\u001b[0;32m----> 5\u001b[0;31m              for x in [s + '_' + MASK + '.tif' for s in file_ids]]\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     pre = preproc.DataPreProcessor(element_size_um=None,\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                (plugin, kind))\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/skimage/io/_plugins/tifffile_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# read and return tiff as numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mTiffFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_tiff\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtif\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/skimage/external/tifffile/tifffile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg, name, offset, size, multifile, multifile_close, pages, fastij, is_ome)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         self._fh = FileHandle(arg, mode='rb',\n\u001b[0;32m-> 1328\u001b[0;31m                               name=name, offset=offset, size=size)\n\u001b[0m\u001b[1;32m   1329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/skimage/external/tifffile/tifffile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, name, offset, size)\u001b[0m\n\u001b[1;32m   3515\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3516\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3517\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3519\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras-gpu/lib/python3.7/site-packages/skimage/external/tifffile/tifffile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/data/DeepFLaSH2/data/labels/gt/0092_Parv.tif'"
     ]
    }
   ],
   "source": [
    "coder_weights = {}\n",
    "coder_masks = {}\n",
    "for coder in CODER:\n",
    "    mask_list = [io.imread(os.path.join(MASK_PATH, coder, x), as_gray=True).astype('int')\n",
    "             for x in [s + '_' + MASK + '.png' for s in file_ids]]\n",
    "    \n",
    "    pre = preproc.DataPreProcessor(element_size_um=None,\n",
    "                               border_weight_sigma_px=SIGMA_SEP,\n",
    "                               foreground_dist_sigma_px=SIGMA_BAL,\n",
    "                               border_weight_factor=LAMBDA,\n",
    "                               foreground_background_ratio=V_BAL\n",
    "                              )\n",
    "    weight_list = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        sampleData, sampleLabels, sampleWeights, samplePdf = pre.generateSample(data[i], classlabels=mask_list[i])\n",
    "        weight_list.append(sampleWeights)  \n",
    "    coder_masks[coder] = mask_list\n",
    "    coder_weights[coder] = weight_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "for i in range(len(data)):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "    axs[0].imshow(data[i]['rawdata'][...,0],cmap='gray', vmin=0, vmax=1)\n",
    "    axs[0].set_axis_off()\n",
    "    axs[1].imshow(coder_masks[coder][i],cmap='gray', vmin=0, vmax=1)\n",
    "    axs[1].set_axis_off()\n",
    "    axs[2].imshow(coder_weights[coder][i],cmap='gray')#, vmin=0, vmax=35)\n",
    "    axs[2].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over coder and folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coder in CODER:\n",
    "    mask_list = coder_masks[coder] \n",
    "    weight_list = coder_weights[coder]\n",
    "    name = NAME_PREFIX + '_' + MASK + '_' + str(CYCLIC_LR) + '_' + coder \n",
    "    output_path = os.path.join('output', name)\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, random_state=SEED)\n",
    "    fold = 0\n",
    "    \n",
    "    for train_index, test_index in skf.split(assignment['Nummer'], assignment['Group_ID']):\n",
    "        fold += 1\n",
    "        if fold < SKIP:\n",
    "            continue\n",
    "        X_train, X_test = np.array(image_list)[train_index], np.array(image_list)[test_index]\n",
    "        y_train, y_test = np.array(mask_list)[train_index], np.array(mask_list)[test_index]\n",
    "        W_train, W_test = np.array(weight_list)[train_index], np.array(weight_list)[test_index]\n",
    "\n",
    "        data_train = [{'rawdata': img, 'element_size_um': EL_SIZE} for img in X_train]\n",
    "        data_test = [{'rawdata': img, 'element_size_um': EL_SIZE} for img in X_test]\n",
    "\n",
    "        ## Generators\n",
    "        train_generator = preproc.DataAugmentationGenerator(data = data_train, \n",
    "                                                        classlabels=y_train,\n",
    "                                                        instancelabels=None,\n",
    "                                                        tile_shape = TILE_SHAPE, \n",
    "                                                        padding= PADDING,\n",
    "                                                        batch_size = 4,\n",
    "                                                        n_classes=2,\n",
    "                                                        ignore=None,\n",
    "                                                        weights=W_train,\n",
    "                                                        element_size_um=None,\n",
    "                                                        rotation_range_deg=(0, 360),\n",
    "                                                        flip=False,\n",
    "                                                        deformation_grid=(150, 150),\n",
    "                                                        deformation_magnitude=(10, 10),\n",
    "                                                        value_minimum_range=(0, 0),\n",
    "                                                        value_maximum_range=(0.0, 1),\n",
    "                                                        value_slope_range=(1, 1),\n",
    "                                                        shuffle=True,\n",
    "                                                        foreground_dist_sigma_px=SIGMA_BAL,\n",
    "                                                        border_weight_sigma_px=SIGMA_SEP,\n",
    "                                                        border_weight_factor=LAMBDA,\n",
    "                                                        foreground_background_ratio=V_BAL\n",
    "                                                       )\n",
    "        test_generator = preproc.TileGenerator(data = data_test,\n",
    "                                           classlabels=y_test,\n",
    "                                           instancelabels=None,\n",
    "                                           tile_shape = TILE_SHAPE, \n",
    "                                           padding= PADDING,\n",
    "                                           n_classes=2,\n",
    "                                           ignore=None,\n",
    "                                           weights=W_test,\n",
    "                                           element_size_um=EL_SIZE,                                       \n",
    "                                           foreground_dist_sigma_px=SIGMA_BAL,\n",
    "                                           border_weight_sigma_px=SIGMA_SEP,\n",
    "                                           border_weight_factor=LAMBDA,\n",
    "                                           foreground_background_ratio=V_BAL)\n",
    "\n",
    "        ## Model\n",
    "        utils.reset_keras()\n",
    "        name_helper = name + '_' + str(fold)\n",
    "\n",
    "        print(name_helper)\n",
    "        \n",
    "        model = unet.Unet2D(snapshot=None, \n",
    "                        n_channels=1, \n",
    "                        n_classes=2, \n",
    "                        n_levels=4,\n",
    "                        batch_norm = BATCH_NORM,\n",
    "                        upsample=False,\n",
    "                        relu_alpha=0.1,\n",
    "                        n_features=64, name=name_helper)\n",
    "\n",
    "        if PRETAINED is not None: \n",
    "            model.trainModel.load_weights(PRETAINED,reshape=True, by_name=True)\n",
    "\n",
    "        model.train(train_generator, \n",
    "                validation_generator=test_generator, \n",
    "                n_epochs=EPOCHS, \n",
    "                snapshot_interval= SNAPSHOT_INTERVAL,\n",
    "                snapshot_dir = CHECKPOINTS,\n",
    "                snapshot_prefix=name_helper,\n",
    "                log_dir = LOGDIR,\n",
    "                cyclic_lr= CYCLIC_LR)\n",
    "\n",
    "        ## Predict\n",
    "        pred_model = unet.Unet2D(snapshot= CHECKPOINTS + '/' +name_helper+'.0100.h5',\n",
    "                        n_channels=1, \n",
    "                        n_classes=2, \n",
    "                        n_levels=4, \n",
    "                        batch_norm =  BATCH_NORM,\n",
    "                        upsample=False,\n",
    "                        relu_alpha=0.1,\n",
    "                        n_features=64,name=\"U-Net\")\n",
    "\n",
    "        tile_generator = preproc.TileGenerator(data_test, TILE_SHAPE, PADDING)\n",
    "\n",
    "        predictions = pred_model.predict(test_generator)\n",
    "        ## Save\n",
    "        for i in range(len(predictions[1])):\n",
    "            idx = np.array(file_ids)[test_index][i]\n",
    "            file_name = idx + '_' + MASK + '.png'\n",
    "            io.imsave(os.path.join(output_path, file_name), predictions[1][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
